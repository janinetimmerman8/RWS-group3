{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main notebook for the midterm submission from RWS group 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. Analysis of incident data\n",
    "2. The travel time of the road sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing all neccesary modules\n",
    "%matplotlib inline\n",
    "import geopandas as gpd\n",
    "import folium \n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from folium.plugins import HeatMap\n",
    "from folium.plugins import MarkerCluster\n",
    "import branca.colormap as cm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analysis of incident data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Preparation work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def DutchRDtoWGS84(rdX, rdY):\n",
    "    \"\"\" Convert DutchRD to WGS84\n",
    "    \"\"\"\n",
    "    RD_MINIMUM_X = 11000\n",
    "    RD_MAXIMUM_X = 280000\n",
    "    RD_MINIMUM_Y = 300000\n",
    "    RD_MAXIMUM_Y = 630000\n",
    "    if (rdX < RD_MINIMUM_X or rdX > RD_MAXIMUM_X\n",
    "        or rdY < RD_MINIMUM_Y or rdY > RD_MAXIMUM_Y):\n",
    "        resultNorth = -1\n",
    "        resultEast = -1\n",
    "        return resultNorth, resultEast\n",
    "    # else\n",
    "    dX = (rdX - 155000.0) / 100000.0\n",
    "    dY = (rdY - 463000.0) / 100000.0\n",
    "    k = [[3600 * 52.15517440, 3235.65389, -0.24750, -0.06550, 0.0],\n",
    "        [-0.00738   ,   -0.00012,  0.0    ,  0.0    , 0.0],\n",
    "        [-32.58297   ,   -0.84978, -0.01709, -0.00039, 0.0],\n",
    "        [0.0       ,    0.0    ,  0.0    ,  0.0    , 0.0],\n",
    "        [0.00530   ,    0.00033,  0.0    ,  0.0    , 0.0],\n",
    "        [0.0       ,    0.0    ,  0.0    ,  0.0    , 0.0]]\n",
    "    l = [[3600 * 5.38720621,    0.01199,  0.00022,  0.0    , 0.0],\n",
    "        [5260.52916   ,  105.94684,  2.45656,  0.05594, 0.00128],\n",
    "        [-0.00022   ,    0.0    ,  0.0    ,  0.0    , 0.0],\n",
    "        [-0.81885   ,   -0.05607, -0.00256,  0.0    , 0.0],\n",
    "        [0.0       ,    0.0    ,  0.0    ,  0.0    , 0.0],\n",
    "        [0.00026   ,    0.0    ,  0.0    ,  0.0    , 0.0]]\n",
    "    resultNorth = 0\n",
    "    resultEast = 0\n",
    "    powX = 1\n",
    "\n",
    "    for p in range(6):\n",
    "        powY = 1\n",
    "        for q in range(5):\n",
    "            resultNorth = resultNorth + k[p][q] * powX * powY / 3600.0\n",
    "            resultEast = resultEast + l[p][q] * powX * powY / 3600.0\n",
    "            powY = powY * dY\n",
    "        powX = powX * dX\n",
    "    return resultNorth, resultEast\n",
    "\n",
    "def WGS84toDutchRD(wgs84East, wgs84North):\n",
    "    # translated from Peter Knoppers's code\n",
    "\n",
    "    # wgs84East: longtitude\n",
    "    # wgs84North: latitude\n",
    "\n",
    "    # Western boundary of the Dutch RD system. */\n",
    "    WGS84_WEST_LIMIT = 3.2\n",
    "\n",
    "    # Eastern boundary of the Dutch RD system. */\n",
    "    WGS84_EAST_LIMIT = 7.3\n",
    "\n",
    "    # Northern boundary of the Dutch RD system. */\n",
    "    WGS84_SOUTH_LIMIT = 50.6\n",
    "\n",
    "    # Southern boundary of the Dutch RD system. */\n",
    "    WGS84_NORTH_LIMIT = 53.7\n",
    "\n",
    "    if (wgs84North > WGS84_NORTH_LIMIT) or \\\n",
    "        (wgs84North < WGS84_SOUTH_LIMIT) or \\\n",
    "        (wgs84East < WGS84_WEST_LIMIT) or \\\n",
    "        (wgs84East > WGS84_EAST_LIMIT):\n",
    "        resultX = -1\n",
    "        resultY = -1\n",
    "    else:\n",
    "        r = [[155000.00, 190094.945,   -0.008, -32.391, 0.0],\n",
    "            [-0.705, -11832.228,    0.0  ,   0.608, 0.0],\n",
    "            [0.0  ,   -114.221,    0.0  ,   0.148, 0.0],\n",
    "            [0.0  ,     -2.340,    0.0  ,   0.0  , 0.0],\n",
    "            [0.0  ,      0.0  ,    0.0  ,   0.0  , 0.0]]\n",
    "        s = [[463000.00 ,      0.433, 3638.893,   0.0  ,  0.092],\n",
    "            [309056.544,     -0.032, -157.984,   0.0  , -0.054],\n",
    "            [73.077,      0.0  ,   -6.439,   0.0  ,  0.0],\n",
    "            [59.788,      0.0  ,    0.0  ,   0.0  ,  0.0],\n",
    "            [0.0  ,      0.0  ,    0.0  ,   0.0  ,  0.0]]\n",
    "        resultX = 0\n",
    "        resultY = 0\n",
    "        powNorth = 1\n",
    "        dNorth = 0.36 * (wgs84North - 52.15517440)\n",
    "        dEast = 0.36 * (wgs84East - 5.38720621)\n",
    "\n",
    "        for p in range(5):\n",
    "            powEast = 1\n",
    "            for q in range(5):\n",
    "                resultX = resultX + r[p][q] * powEast * powNorth\n",
    "                resultY = resultY + s[p][q] * powEast * powNorth\n",
    "                powEast = powEast * dEast\n",
    "            powNorth = powNorth * dNorth\n",
    "    return resultX, resultY\n",
    "\n",
    "def calc_distance(line_wkt):\n",
    "    line = ogr.CreateGeometryFromWkt(line_wkt)\n",
    "    points = line.GetPoints()\n",
    "    d = 0\n",
    "    for p0, p1 in zip(points, points[1:]):\n",
    "        d = d + geodesic(p0, p1).m\n",
    "    return d\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    x, y = WGS84toDutchRD(4.33, 52.04)\n",
    "    print(DutchRDtoWGS84(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract subnetwork\n",
    "highway_shapefile = 'Shapefiles/Snelheid_Wegvakken.shp'\n",
    "network_temp = gpd.read_file(highway_shapefile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_temp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('incidents19Q3Q4.csv')\n",
    "df.columns = ['index', 'id', 'type', 'start_time','end_time', 'road_number','longitude','latitude']\n",
    "df['start_time'] = pd.to_datetime(df['start_time'])\n",
    "df['end_time'] = pd.to_datetime(df['end_time'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Filtering: \n",
    "A function that can:\n",
    "- (1) Delete the incidents which are not occured on the high ways \n",
    "- (2) Delete the incidents which the values for road number is missing \n",
    "- (3) Change name of all roads 'hrb'\n",
    "- (4) Delete the incidents that are out of the border of the Netherlands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_filter(data_input):\n",
    "    data_input = df.dropna()\n",
    "    data_input.loc[:,'road_number'] = data_input['road_number'].replace({'A12 hrb':'A12', 'A16 hrb':'A16', 'A2 hrb':'A2'})\n",
    "    new_data = data_input[data_input['road_number'].str.startswith('A')]\n",
    "    new_data.drop(new_data.loc[new_data['index'] == 183130].index, inplace=True)\n",
    "    \n",
    "    return new_data\n",
    "incidents_df = data_filter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Mark all incidents at the road network in heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_incidents(filter_type, keyword):\n",
    "\n",
    "    # Define a new map\n",
    "    m = folium.Map(location=[52.399190, 4.893658])\n",
    "\n",
    "    if filter_type == 'Incident_type':\n",
    "        new_data = incidents_df.loc[incidents_df['type'] == keyword]\n",
    "        # Extract the latitude and longitude as a list of lists\n",
    "        heat_data = [[row['latitude'], row['longitude']] for _, row in new_data.iterrows()]\n",
    "        # Create a heatmap layer\n",
    "        HeatMap(heat_data).add_to(m)\n",
    "    return m\n",
    "\n",
    "map_new = draw_incidents('Incident_type', 'accident')\n",
    "map_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Analysis of time periods when incidents occurs (starting time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw a bar chart show the distribution of time when incidents occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df['hour_of_day'] = incidents_df['start_time'].apply(lambda x: x.hour)\n",
    "hourly_counts = incidents_df.groupby('hour_of_day').size().reset_index(name='accident_count')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(hourly_counts['hour_of_day'], hourly_counts['accident_count'])\n",
    "plt.xlabel('Hour of a day')\n",
    "plt.ylabel('Accidents count')\n",
    "plt.title('Accident count by hour of day')\n",
    "plt.xticks(hourly_counts['hour_of_day'])\n",
    "\n",
    "plt.axvspan(0, 5, alpha=0.2, color='red', label='0-5h')\n",
    "plt.axvspan(6, 9, alpha=0.2, color='black', label='6-9h')\n",
    "plt.axvspan(10, 14, alpha=0.2, color='green', label='10-14h')\n",
    "plt.axvspan(15, 18, alpha=0.2, color='yellow', label='15-18h')\n",
    "plt.axvspan(19, 23, alpha=0.2, color='orange', label='19-23h')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the probability of accident of time of a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probability of time of a day for incident\n",
    "pro_0_5h = hourly_counts['accident_count'][:6].sum() / hourly_counts['accident_count'].sum()\n",
    "pro_6_9h = hourly_counts['accident_count'][6:10].sum() / hourly_counts['accident_count'].sum()\n",
    "pro_10_14h = hourly_counts['accident_count'][10:15].sum() / hourly_counts['accident_count'].sum()\n",
    "pro_15_18h =hourly_counts['accident_count'][15:19].sum() / hourly_counts['accident_count'].sum()\n",
    "pro_19_23h = hourly_counts['accident_count'][19:].sum() / hourly_counts['accident_count'].sum()\n",
    "\n",
    "result_data = {\n",
    "    'Time Range': ['0-5 hours', '6-9 hours', '10-14 hours', '15-18 hours', '19-23 hours'],\n",
    "    'Probability': [pro_0_5h, pro_6_9h, pro_10_14h, pro_15_18h, pro_19_23h]\n",
    "}\n",
    "\n",
    "pro_time = pd.DataFrame(result_data)\n",
    "pro_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3 Analysis of day of week when incidents occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the probability of accident of time of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df['day of week'] = incidents_df ['start_time'].dt.dayofweek\n",
    "weekly_count = incidents_df['day of week'].value_counts(normalize=True)\n",
    "day_mapping = {\n",
    "    0: 'Monday',\n",
    "    1: 'Tuesday',\n",
    "    2: 'Wednesday',\n",
    "    3: 'Thursday',\n",
    "    4: 'Friday',\n",
    "    5: 'Saturday',\n",
    "    6: 'Sunday'\n",
    "}\n",
    "weekly_count.index = weekly_count.index.map(day_mapping)\n",
    "\n",
    "pro_weekly = pd.DataFrame({\n",
    "    'Day of Week': weekly_count.index,\n",
    "    'Probability': weekly_count.values\n",
    "})\n",
    "pro_weekly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw a bar chart to visualize the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(pro_weekly['Day of Week'], pro_weekly['Probability'])\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Probability of incident occuring on different days of a week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.4 Analysis of accident frequency and duration time in each highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of accidents in each road\n",
    "accidents_number = incidents_df.groupby('road_number').size()\n",
    "accidents_df = accidents_number.reset_index()\n",
    "accidents_df.columns = ['road_number', 'accidents_number']\n",
    "\n",
    "# count the average lasting time for each road\n",
    "incidents_df['Duration_time'] = (incidents_df['end_time'] - incidents_df['start_time']).dt.total_seconds() / 60\n",
    "average_duration_by_road = incidents_df.groupby('road_number')['Duration_time'].mean()\n",
    "duration_df = average_duration_by_road.reset_index()\n",
    "duration_df.columns = ['road_number', 'average_duration']\n",
    "\n",
    "# Mix them and create the new dataframe\n",
    "road_number_counts = pd.merge(accidents_df, duration_df, on='road_number', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_number_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Show the incident hot spots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use DBSCAN (Density-Based Spatial Clustering of Applications with Noise) clustering algorithm to show hotspots of incident, which is based on density of incidents in map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_clusters(eps, min_samples, data):\n",
    "   \n",
    "    # Create a DBSCAN clustering model\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric='haversine', algorithm='ball_tree')\n",
    "\n",
    "    # Fit the model to the latitude and longitude data\n",
    "    dbscan.fit(data[['latitude', 'longitude']].values)\n",
    "\n",
    "    # Assign cluster labels to data points\n",
    "    data['cluster'] = dbscan.labels_\n",
    "\n",
    "    # Filter out noise points (-1 labels)\n",
    "    clustered_data = data[data['cluster'] != -1]\n",
    "\n",
    "    m = folium.Map(location=[52.399190, 4.893658], zoom_start=8, zoom_control=False)\n",
    "\n",
    "    # Create a MarkerCluster layer for clustered data\n",
    "    marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "    # Add markers for clustering\n",
    "    for _, row in clustered_data.iterrows():\n",
    "        popup_text = f\"Cluster: {row['cluster']}<br>Type: {row['type']}<br>Index: {row['index']}\"\n",
    "        folium.Marker([row['latitude'], row['longitude']], icon=None, popup=popup_text).add_to(marker_cluster)\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "# Call the function to visualize clusters with markers and centroids\n",
    "clustered_map = draw_clusters(eps=0.1, min_samples=100, data=incidents_df)\n",
    "clustered_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can show the specific longitude and langtitude of each hotspot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The travel time of the road sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the speed of the road section will be determined. Together with the length of each road section, the travel time of each section can be deterined. For the full notebook with all explanations. See **speed_network_data.ipynb**. \n",
    "\n",
    "This section will only show the results obtained from the speed_network_data notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First there is the following dataframe. It has been obtained by combining the given shapefiles, open source wkd (\"Wegkenmerkendatabase\") data about the maximum speed and INWEVA (\"INtensiteit WEgVAkken\") data which gives traffic intensities on road sections. There was some missing data, which has been filled with data from adjacent road sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_section_data = pd.read_csv('speed_data', sep=';')\n",
    "road_section_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the travel time of each road section has been estimated in optimal conditions (the average speed equals the speed limit) and the speed during peak hours. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from the dataframe has also been converted to a NetworkX graph. This graph can later be used in the optimization methods to calculate the travel time of the shortest path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = pickle.load(open('NetworkX_graph.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph contains all edges with several attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the data of a random edge\n",
    "G.edges[list(G.edges)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_clusters(k_value, data):\n",
    "    # Create a K-Means clustering model\n",
    "    kmeans = KMeans(n_clusters=k_value)\n",
    "\n",
    "    # Fit the model to the latitude and longitude data\n",
    "    locations = data[['latitude', 'longitude']].values\n",
    "    kmeans.fit(locations)\n",
    "\n",
    "    # Assign cluster labels to data points\n",
    "    data['cluster'] = kmeans.labels_\n",
    "\n",
    "    m = folium.Map(location=[np.mean(locations[:, 0]), np.mean(locations[:, 1])], zoom_start=8, zoom_control=False)\n",
    "\n",
    "    # Create a MarkerCluster layer for clustered data\n",
    "    marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "    # Add markers for clustering\n",
    "    for cluster_label in range(k_value):\n",
    "        cluster_data = data[data['cluster'] == cluster_label]\n",
    "        for _, row in cluster_data.iterrows():\n",
    "            popup_text = f\"Cluster: {row['cluster']}<br>Type: {row['type']}<br>Index: {row['index']}\"\n",
    "            folium.Marker([row['latitude'], row['longitude']], icon=None, popup=popup_text).add_to(marker_cluster)\n",
    "\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    for i, center in enumerate(cluster_centers):\n",
    "        center_popup_text = f\"Cluster Center {i + 1}\"\n",
    "        folium.Marker([center[0], center[1]], icon=folium.Icon(color='red'), popup=center_popup_text).add_to(m)\n",
    "\n",
    "    return m\n",
    "\n",
    "k_value = 20  # Set the number of clusters\n",
    "clustered_map = draw_clusters(k_value, incidents_df)\n",
    "clustered_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
